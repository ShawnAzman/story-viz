{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## see if scene text can be found in chapter file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load json data\n",
    "story = \"alice\"\n",
    "with open(f\"../src/data/{story}-new.json\") as f:\n",
    "    data = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "chapters_folder = f\"chapters/{story}/\"\n",
    "chapters = data[\"chapters\"]\n",
    "scenes = data[\"scenes\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "for chap in chapters:\n",
    "    chap_title = chap[\"chapter\"]\n",
    "    chap_text_file = f\"{chapters_folder}{chap_title}.txt\"\n",
    "    with open(chap_text_file, \"r\") as f:\n",
    "        chap_text = f.read()\n",
    "\n",
    "    # only take text after \": \" in each line\n",
    "    chap_text = \"\\n\".join([line.split(\": \", 1)[1] for line in chap_text.split(\"\\n\") if \": \" in line])\n",
    "\n",
    "    chap_scenes = [scene for scene in scenes if scene[\"chapter\"] == chap_title]\n",
    "    for scene in chap_scenes:\n",
    "        scene_num = scene[\"number\"]\n",
    "        scene_title = scene[\"title\"]\n",
    "        scene_text = scene[\"text\"]\n",
    "        \n",
    "        if scene_text not in chap_text:\n",
    "            print(f\"Scene {chap_title}-{scene_title} (scene #{scene_num}) not found in {chap_title}.\")\n",
    "            # print(f\"Scene text: {scene_text}\")\n",
    "            # print(f\"Chapter text: {chap_text}\")\n",
    "            print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## check if chapters in public match those in notebooks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(31,\n",
       " ['alice',\n",
       "  'anne',\n",
       "  'artofwar',\n",
       "  'bookstore',\n",
       "  'color',\n",
       "  'donquixote',\n",
       "  'emma',\n",
       "  'faust',\n",
       "  'frankenstein',\n",
       "  'gatsby',\n",
       "  'genji',\n",
       "  'greatexp',\n",
       "  'hamlet',\n",
       "  'iliad',\n",
       "  'littlewomen',\n",
       "  'marrow',\n",
       "  'mendips',\n",
       "  'metamorphosis',\n",
       "  'odyssey',\n",
       "  'pride',\n",
       "  'redchamber',\n",
       "  'romeo',\n",
       "  'starlight',\n",
       "  'threads',\n",
       "  'time',\n",
       "  'trial',\n",
       "  'ulysses',\n",
       "  'victoria',\n",
       "  'war',\n",
       "  'whispers',\n",
       "  'wizard'])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# list public chapter folder names\n",
    "public_chapter_folder = f\"../public/chapters/\"\n",
    "\n",
    "ignore_stories = [\"yourname\"]\n",
    "\n",
    "public_chapters = os.listdir(public_chapter_folder)\n",
    "public_chapters = [chap for chap in public_chapters if os.path.isdir(public_chapter_folder + chap)]\n",
    "public_chapters = sorted([chap for chap in public_chapters if chap not in ignore_stories])\n",
    "\n",
    "len(public_chapters), public_chapters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "for story in public_chapters:\n",
    "    # compare each .txt file in this folder with the corresponding chapter in the json file\n",
    "    chapters_folder = f\"{public_chapter_folder}/{story}/\"\n",
    "    notebook_chapter_folder = f\"chapters/{story}/\"\n",
    "    public_txt_files = os.listdir(chapters_folder)\n",
    "    public_txt_files = [f for f in public_txt_files if f.endswith(\".txt\")]\n",
    "    public_txt_files = sorted(public_txt_files)\n",
    "\n",
    "    for pf in public_txt_files:\n",
    "        # load in txt file\n",
    "        with open(chapters_folder + pf, \"r\") as f:\n",
    "            chap_text = f.read()\n",
    "        \n",
    "        # load corresponding chapter txt from notebook_chapter_folder\n",
    "        with open(f\"{notebook_chapter_folder}{pf}\", \"r\") as f:\n",
    "            notebook_chap_text = f.read()\n",
    "        \n",
    "        if chap_text != notebook_chap_text:\n",
    "            print(f\"Chapter {pf} in {story} does not match.\")\n",
    "            # find problematic lines\n",
    "            chap_text_lines = chap_text.split(\"\\n\")\n",
    "            notebook_chap_text_lines = notebook_chap_text.split(\"\\n\")\n",
    "\n",
    "            for i, (line1, line2) in enumerate(zip(chap_text_lines, notebook_chap_text_lines)):\n",
    "                if line1 != line2:\n",
    "                    print(f\"Line {i}:\")\n",
    "                    print(f\"  {line1}\")\n",
    "                    print(f\"  {line2}\")\n",
    "                    print()\n",
    "            print()\n",
    "            print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "story-viz-mNgXibik",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
